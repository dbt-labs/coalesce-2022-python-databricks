{"cells":[{"cell_type":"markdown","source":["# Coalesce 2022 Python models on Databricks workshop\n\n**Important**: replace the schema below with your own."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7786426-7f1a-4058-840e-541b0935db6c"}}},{"cell_type":"code","source":["# IMPORTANT: replace the schema\nschema = \"dbt_cody\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ed3a81f-ee85-4714-8b46-8e0b649d5cb6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# \"spark\" is the canonical magical Spark session object\n# variety is the spice of life\nsession = spark\ns = session"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7e7b546-90b4-45eb-a606-91de3507b2aa"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Level 1: Describe the orders table\n\nCompute summary statistics about the orders table.\n\nHint: check out the `describe()` method from pandas (on Spark). Do you want to work with PySpark DataFrames, or pandas on Spark DataFrames?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3b873e23-4fbd-4259-9d08-f7059ca81ed9"}}},{"cell_type":"code","source":["orders = s.table(f\"{schema}.orders\")\norders"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06fa946b-0002-466f-ab32-9ebb9f41d178"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["type(orders)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b7857f3-da55-49fb-b40c-ace2069275c4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Level 2: Pivot the orders table\n\nOrders contains most important details, but is lacking the breakdown by product_id. Add the subtotal for each product_id to the orders table.\n\nHint: this can be achieved in dataframes generally via `pivot` methods. Can you find a better way?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2f174cf1-3075-43e6-a698-248364ae64b0"}}},{"cell_type":"code","source":["stg_products = s.table(f\"{schema}.stg_products\")\nstg_products"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3d22c20e-4c44-44d5-bef1-5edb5588f963"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["stg_order_items = s.table(f\"{schema}.stg_order_items\")\nstg_order_items"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a92fda55-eeba-4cc9-b252-c61db487a6d5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Level 3: Cluster with KMeans\n\nYou suspect there are N personas representing customers. Attempt to group the data from \"Level 2\" into N clusters so that it can be further analyzed.\n\nHint: create a `X` array for use in KMeans and PCA below."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9412be01-88b3-4432-ac7f-1ea0e25b247a"}}},{"cell_type":"code","source":["# use the dataframe object from above, or cheat and use the pivot_py model from an already built schema\norders_with_subtotals = s.table(f\"{schema}.pivot_py\")\norders_with_subtotals"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ab4bde74-1dd9-4f79-b632-afb474b73d2d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import pyspark.pandas as ps\n\nfrom sklearn.cluster import KMeans"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7676828c-d7f7-4750-87dd-afdcb61f8b48"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["n_clusters = 5"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a1afcf1-086e-41f0-8041-3cd5ec14db70"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["X = None # engineer features for the KMeans model\ncluster_labels = None # predict from the KMeans model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fad001ff-316b-4162-8c07-f73984a10edd"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# visualize the clusters\n\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\nn_components = 3\npca = PCA(n_components=n_components)\npca = pca.fit(X)\nX_pca = pca.transform(X)\n\nfig = plt.figure(figsize=(8, 8))\nax = fig.add_subplot(projection=\"3d\")\n\nax.scatter(\n    X_pca[:, 0],\n    X_pca[:, 1],\n    X_pca[:, 2],\n    c=cluster_labels, # how do you get these?\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4702150-3fdd-4012-9d58-085d4954db6e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# example of joining the KMeans predictions with the original dataframe\n# not necessarily working. create X, get the predictions, then \norders_with_subtotals_and_clusters = orders_with_subtotals.merge(\n    ps.DataFrame(data=cluster_labels, columns=[\"cluster_label\"]),\n    left_index=True,\n    right_index=True"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"544afa38-1efa-4136-a7c2-7fdcbd4774db"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Level 4: Forecast with Prophet\n\nForecast revenue with Prophet models for each location_id."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5fb26265-2d79-4fe5-9ba7-f05bae026154"}}},{"cell_type":"code","source":["from prophet import Prophet\nfrom prophet.serialize import model_to_json, model_from_json"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39589e8e-d4ed-4437-ae3a-f63a12478666"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["revenue = s.table(f\"{schema}.revenue_weekly_by_location\").pandas_api()\nrevenue.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a8e67415-c44d-4bb0-8883-3a4e114920d9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# at the end, something like this should work to plot the forecasts\n# note that `.plot(...)` here is a Prophet model's method\nfor location in locations:\n    models[location].plot(forecasts[location])\n    plt.title(location)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ebf0a4be-4d7e-40ea-863d-ec4bb9adb8fc"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now how do you run these models in dbt? Can you save them in one (dbt) model, and load them in another?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3c33bf24-16dd-469b-8742-b703c7f274c7"}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39799483-cb51-4a1e-88e2-66c9a781395d"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"workshop.ipynb","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3281015056516742}},"nbformat":4,"nbformat_minor":0}
